# -*- coding: utf-8 -*-
"""MVP_EduardoMoutinho.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/github/Edmout/Machine-Learning-MVP/blob/main/MVP_EduardoMoutinho.ipynb

## **Classificador de diagnóstico de câncer de mama**
**Contexto:** Temos um conjunto de dados de diagnóstico de cancer de mama em Wiscosin que representam as características dos núcleos celulares presentes em uma imagem digitalizada de um aspirado com agulha fina (PAAF) de uma massa mamária. O objetivo deste notebook é criar um modelo de visão computacional que consiga realizar a partir destas características uma classificação diagnóstica de tumores na mama entre as opções: M - Malígno ou B- Benígno.

**Estrutura:** O notebook está dividido assim:

1- Importação das bibliotecas

2 - Preparação de Dados

3 - Modelagem e treinamento

4 - Finalização do modelo

5- Simulando a aplicação do modelo em dados não vistos

**Dataset:** O dataset é originário do repositório de Machine Learning da UC Irvine para uso didático e também está disponível na biblioteca Scikit-Learn, de onde foi importado para este notebook. Os atributos são estas dez características de valor real calculadas para cada núcleo celular:

 - raio (média das distâncias do centro aos pontos do perímetro)
 - textura (desvio padrão dos valores da escala de cinza)
 - perímetro
 - área
 - suavidade (variação local nos comprimentos dos raios)
 - compacidade (perímetro^2 / área - 1,0)
 - concavidade (severidade das porções côncavas do contorno)
 - pontos côncavos (número de porções côncavas do contorno)
 - simetria
 - dimensão fractal ("aproximação do litoral" - 1)

 A média, o erro padrão e o "pior" ou maior (média dos três piores/maiores valores) dessas características foram computados para cada imagem, resultando em 30 funcionalidades. Por exemplo, o campo 0 é Raio Médio, campo 10 é Raio SE, campo 20 é Pior Raio.

 Número de Instâncias: 569

 Número de atributos: 30 atributos numéricos, preditivos e a classe

 Distribuição das classes: 212 - Maligno, 357 - Benigno

 Classe:
  - WDBC-Maligno
  - WDBC-Benigno

Para mais informações sobre o dataset, veja o link a seguir: https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic

##  1 - Importação das bibliotecas
"""

# Importando as bibliotecas necessárias para executar o notebook
# configuração para não exibir os warnings
import warnings
warnings.filterwarnings("ignore")

# Imports necessários
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import load_breast_cancer # para importar o dataset breast_cancer
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split # para particionar em bases de treino e teste (holdout)
from sklearn.model_selection import KFold # para preparar os folds da validação cruzada
from sklearn.model_selection import StratifiedKFold # validação cruzada com estratificação
from sklearn.model_selection import cross_val_score # para executar a validação cruzada
from sklearn.model_selection import GridSearchCV # para executar a otimização dos hiperparâmetros
from sklearn.feature_selection import SelectKBest # para a Seleção Univariada
from sklearn.feature_selection import f_classif # para o teste ANOVA da Seleção Univariada
from sklearn.feature_selection import RFE # para a Eliminação Recursiva de Atributos
from sklearn.metrics import accuracy_score # para a exibição da acurácia do modelo
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression # Regressão Logística, para a Eliminação Recursiva de Atributos
from sklearn.tree import DecisionTreeClassifier # algoritmo Árvore de Classificação
from sklearn.neighbors import KNeighborsClassifier # algoritmo KNN
from sklearn.naive_bayes import GaussianNB # algoritmo Naive Bayes
from sklearn.svm import SVC # algoritmo SVM
from sklearn.ensemble import BaggingClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import ExtraTreesClassifier
from sklearn.ensemble import VotingClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.ensemble import GradientBoostingClassifier

"""## 2 - Preparação de Dados

### *Carga do Dataset*

Realizando a carga do dataset breast_cancer e exibindo as primeiras linhas
"""

# Importação do dataset
breast_cancer = load_breast_cancer()

# Caso deseje fazer a carga do dataset a partir do GitHub
# Informa a URL de importação do dataset
#url_dados = 'https://raw.githubusercontent.com/Edmout/Machine-Learning-MVP/68b20efd0e8480943729580ae21595b2c1280151/wdbc.data'

# labels dos atributos do dataset
#labels_atributos = ['mean radius', 'mean texture', 'mean perimeter', 'mean area',
#       'mean smoothness', 'mean compactness', 'mean concavity',
#       'mean concave points', 'mean symmetry', 'mean fractal dimension',
#       'radius error', 'texture error', 'perimeter error', 'area error',
#       'smoothness error', 'compactness error', 'concavity error',
#       'concave points error', 'symmetry error', 'fractal dimension error',
#       'worst radius', 'worst texture', 'worst perimeter', 'worst area',
#       'worst smoothness', 'worst compactness', 'worst concavity',
#       'worst concave points', 'worst symmetry', 'worst fractal dimension']

# carga do dataset através do csv
#dataset = pd.read_csv(url_dados, names=labels_atributos)

dataset = pd.DataFrame(breast_cancer.data, columns=breast_cancer.feature_names) # conversão para dataframe
dataset['target'] = breast_cancer.target # adição da coluna target

# Mostra as primeiras linhas do dataset
dataset.head()

# Visualizando o número de linhas e colunas do dataset
dataset.shape

"""### *Separação do dataset em conjunto de treino e conjunto de teste com holdout*

Realizando a separação em bases de treino e teste por meio do método holdout efetuando a divisão 80% base de treino e 20% base de teste
"""

test_size = 0.20 # tamanho do conjunto de teste
seed = 7 # semente aleatória

# Separação em conjuntos de treino e teste
array = dataset.values
x_ini = array[:,0:30]
y = array[:,30]
X_train, X_test, y_train, y_test = train_test_split(x_ini, y,
    test_size=test_size, shuffle=True, random_state=seed, stratify=y) # holdout com estratificação

"""### *Realizando processo de Feature Selection*

Foram testados os métodos de seleção univariada, eliminação de recursos de atributos e importância de atributos para realizar feature selection, sendo escolhido o método de seleção univariada com redução para 4 atributos que obteve um resultado satisfatório de acurácia nos modelos testados.
"""

# SelectKBest

# Seleção de atributos com SelectKBest
best_var = SelectKBest(score_func=f_classif, k=4)

# Executa a função de pontuação em (x_ini, y) e obtém os atributos selecionados
fit = best_var.fit(x_ini, y)

# Reduz x_ini para os atributos selecionados em x
x = fit.transform(x_ini)

# Resultados
print('\nNúmero original de atributos:', x_ini.shape[1])
print('\nNúmero reduzido de atributos:', x.shape[1])

# Exibe os atributos orginais
print("\nAtributos Originais:", dataset.columns[0:30])

# Exibe as pontuações de cada atributos e os 4 escolhidas (com as pontuações mais altas)
np.set_printoptions(precision=3) # 3 casas decimais
print("\nScores dos Atributos Originais:", fit.scores_)
print("\nAtributos Selecionados:", best_var.get_feature_names_out(input_features=dataset.columns[0:30]))

"""### *Realizando a validação cruzada*

Realizando a separação em 10 folds usando a validação cruzada.
"""

# Parâmetros e partições da validação cruzada
scoring = 'accuracy'
num_particoes = 10
kfold = StratifiedKFold(n_splits=num_particoes, shuffle=True, random_state=seed) # validação cruzada com estratificação

"""## 3 - Modelagem e Treinamento

### Criação e avaliação de modelos: linha base

Realizando a etapa de modelagem e inferência, definindo inicialmente uma semente global para essa célula de código, necessária para garantir a reprodutibilidade do código com os mesmos resultados. Como não sabemos de antemão quais algoritmos performarão bem nesse conjunto de dados, usaremos a validação cruzada para treinar e avaliar os modelos usando a métrica acurácia. Primeiramente, iremos avaliar os algoritmos Regressão Logística, KNN, Árvore de Classificação, Naive Bayes, SVM e Ensembles com a configuração padrão de hiperparâmetros da Scikit-Learn. O resultado médio da acurácia de cada modelo será impresso, bem como um gráfico boxplot sumarizando os resultados das dez execuções (correspondentes aos dez folds)
"""

np.random.seed(7) # definindo uma semente global

# Lista que armazenará os modelos
models = []

# Criando os modelos e adicionando-os na lista de modelos
models.append(('LR', LogisticRegression(max_iter=200)))
models.append(('KNN', KNeighborsClassifier()))
models.append(('CART', DecisionTreeClassifier()))
models.append(('NB', GaussianNB()))
models.append(('SVM', SVC()))

# Definindo os parâmetros do classificador base para o BaggingClassifier
base = DecisionTreeClassifier()
num_trees = 100
max_features = 3

# Criando os modelos para o VotingClassifier
bases = []
model1 = LogisticRegression(max_iter=200)
bases.append(('logistic', model1))
model2 = DecisionTreeClassifier()
bases.append(('cart', model2))
model3 = SVC()
bases.append(('svm', model3))

# Criando os ensembles e adicionando-os na lista de modelos
models.append(('Bagging', BaggingClassifier(base_estimator=base, n_estimators=num_trees)))
models.append(('RF', RandomForestClassifier(n_estimators=num_trees, max_features=max_features)))
models.append(('ET', ExtraTreesClassifier(n_estimators=num_trees, max_features=max_features)))
models.append(('Ada', AdaBoostClassifier(n_estimators=num_trees)))
models.append(('GB', GradientBoostingClassifier(n_estimators=num_trees)))
models.append(('Voting', VotingClassifier(bases)))

# Listas para armazenar os resultados
results = []
names = []

# Avaliação dos modelos
for name, model in models:
    cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)
    results.append(cv_results)
    names.append(name)
    msg = "%s: %f (%f)" % (name, cv_results.mean(), cv_results.std())
    print(msg)

# Boxplot de comparação dos modelos
fig = plt.figure(figsize=(15,10))
fig.suptitle('Comparação dos Modelos')
ax = fig.add_subplot(111)
plt.boxplot(results)
ax.set_xticklabels(names)
plt.show()

"""### Criação e avaliação de modelos: dados padronizados e normalizados

Em seguida, vamos repetir esse processo, utilizando a biblioteca Pipeline para criar e avaliar os modelos através da validação cruzada com os dados padronizados e normalizados (evitando o data leakage) e comparar o seu resultado com os modelos treinados com o dataset original:
"""

np.random.seed(7) # definindo uma semente global para este bloco

# Listas para armazenar os armazenar os pipelines e os resultados para todas as visões do dataset
pipelines = []
results = []
names = []


# Criando os elementos do pipeline

# Algoritmos que serão utilizados
reg_log = ('LR', LogisticRegression(max_iter=200))
knn = ('KNN', KNeighborsClassifier())
cart = ('CART', DecisionTreeClassifier())
naive_bayes = ('NB', GaussianNB())
svm = ('SVM', SVC())
bagging = ('Bag', BaggingClassifier(base_estimator=base, n_estimators=num_trees))
random_forest = ('RF', RandomForestClassifier(n_estimators=num_trees, max_features=max_features))
extra_trees = ('ET', ExtraTreesClassifier(n_estimators=num_trees, max_features=max_features))
adaboost = ('Ada', AdaBoostClassifier(n_estimators=num_trees))
gradient_boosting = ('GB', GradientBoostingClassifier(n_estimators=num_trees))
voting = ('Voting', VotingClassifier(bases))

# Transformações que serão utilizadas
standard_scaler = ('StandardScaler', StandardScaler())
min_max_scaler = ('MinMaxScaler', MinMaxScaler())


# Montando os pipelines

# Dataset original
pipelines.append(('LR-orig', Pipeline([reg_log])))
pipelines.append(('KNN-orig', Pipeline([knn])))
pipelines.append(('CART-orig', Pipeline([cart])))
pipelines.append(('NB-orig', Pipeline([naive_bayes])))
pipelines.append(('SVM-orig', Pipeline([svm])))
pipelines.append(('Bag-orig', Pipeline([bagging])))
pipelines.append(('RF-orig', Pipeline([random_forest])))
pipelines.append(('ET-orig', Pipeline([extra_trees])))
pipelines.append(('Ada-orig', Pipeline([adaboost])))
pipelines.append(('GB-orig', Pipeline([gradient_boosting])))
pipelines.append(('Vot-orig', Pipeline([voting])))

# Dataset Padronizado
pipelines.append(('LR-padr', Pipeline([standard_scaler, reg_log])))
pipelines.append(('KNN-padr', Pipeline([standard_scaler, knn])))
pipelines.append(('CART-padr', Pipeline([standard_scaler, cart])))
pipelines.append(('NB-padr', Pipeline([standard_scaler, naive_bayes])))
pipelines.append(('SVM-padr', Pipeline([standard_scaler, svm])))
pipelines.append(('Bag-padr', Pipeline([standard_scaler, bagging])))
pipelines.append(('RF-padr', Pipeline([standard_scaler, random_forest])))
pipelines.append(('ET-padr', Pipeline([standard_scaler, extra_trees])))
pipelines.append(('Ada-padr', Pipeline([standard_scaler, adaboost])))
pipelines.append(('GB-padr', Pipeline([standard_scaler, gradient_boosting])))
pipelines.append(('Vot-padr', Pipeline([standard_scaler, voting])))

# Dataset Normalizado
pipelines.append(('LR-norm', Pipeline([min_max_scaler, reg_log])))
pipelines.append(('KNN-norm', Pipeline([min_max_scaler, knn])))
pipelines.append(('CART-norm', Pipeline([min_max_scaler, cart])))
pipelines.append(('NB-norm', Pipeline([min_max_scaler, naive_bayes])))
pipelines.append(('SVM-norm', Pipeline([min_max_scaler, svm])))
pipelines.append(('Bag-norm', Pipeline([min_max_scaler, bagging])))
pipelines.append(('RF-norm', Pipeline([min_max_scaler, random_forest])))
pipelines.append(('ET-norm', Pipeline([min_max_scaler, extra_trees])))
pipelines.append(('Ada-norm', Pipeline([min_max_scaler, adaboost])))
pipelines.append(('GB-norm', Pipeline([min_max_scaler, gradient_boosting])))
pipelines.append(('Vot-norm', Pipeline([min_max_scaler, voting])))

# Executando os pipelines
for name, model in pipelines:
    cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)
    results.append(cv_results)
    names.append(name)
    msg = "%s: %.3f (%.3f)" % (name, cv_results.mean(), cv_results.std()) # formatando para 3 casas decimais
    print(msg)

# Boxplot de comparação dos modelos
fig = plt.figure(figsize=(25,6))
fig.suptitle('Comparação dos Modelos - Dataset original, padronizado e normalizado')
ax = fig.add_subplot(111)
plt.boxplot(results)
ax.set_xticklabels(names, rotation=90)
plt.show()

"""Analisando os resultados, verificamos que, considerando a acurácia média, o modelo treinado com Regressão Logística através da validação cruzada com os dados padronizados apresentou os melhores resultados (98% de acurácia média e desvio-padrão de 2%), indicando que possivelmente seguiríamos com ele como escolha de algoritmo. Nesse caso, já poderíamos contruir um novo modelo, treinado com toda a base de treino.

### Otimização dos hiperparâmetros

Agora iremos utilizar a biblioteca Grid Search para executar a otimização dos hiperparâmetros do algoritmo com melhores resultados pela métrica acurácia que foi a Regressão Logística com os dados padronizados a fim de buscar resultados ainda melhores para este algoritmo. Para tal, tentaremos as penalidades  "l1" para regularização L1 (Lasso) e "l2" para regularização L2 (Ridge), o parâmetro C que indica o inverso da força de regularização (valores menores especificam uma regularização mais forte. Um valor maior de C indica uma menor regularização) com os valores 0.1, 1 e 10, o parâmetro solver, algoritmo usado para otimizar parâmetros, com as opções liblinear e saga e com número máximo de iterações permitidas para a convergência do otimizador com os valores 100, 200 e 300.
"""

# Tuning da Regressão Logística com dados padronizados

np.random.seed(7) # definindo uma semente global para este bloco

# Definir o pipeline
pipeline = Pipeline([
    ('scaler', StandardScaler()),  # Passo de pré-processamento para padronizar os dados
    ('logistic', LogisticRegression())  # Modelo de regressão logística
])

# Definir os parâmetros para ajustar
parameters = {
    'logistic__penalty': ['l1', 'l2'],
    'logistic__C': [0.1, 1, 10],
    'logistic__solver': ['liblinear', 'saga'],
    'logistic__max_iter': [100, 200, 300],
}

# Criar o objeto GridSearchCV
grid = GridSearchCV(estimator=pipeline, param_grid=parameters, scoring=scoring, cv=kfold)

# Ajustar o modelo aos dados
grid.fit(X_train, y_train)

# Melhor combinação de parâmetros
best_params = grid.best_params_
print("Melhores parâmetros encontrados:", best_params)

# Acurácia do modelo com os melhores parâmetros
best_accuracy = grid.best_score_
print("Acurácia com os melhores parâmetros:", best_accuracy)

"""Conseguimos melhorar ainda mais um pouquinho acurácia do algoritmo de regressão logística para o dataset padronizado que já era muito boa e podemos então seguir para etapa de finalização do modelo utilizando os melhores parâmetros para este algorítmo.

## 4 - Finalização do Modelo

Vamos agora finalizar o modelo escolhido com o que alcançou os melhores resultados que foi a regressão logística com os dados padronizados. A seguir, finalizaremos esse modelo, treinando-o em todo o conjunto de dados de treinamento (sem validação cruzada e utilizando os melhores parâmetros identificados na etapa anterior), e faremos predições para o conjunto de dados de teste que foi separado logo no início da prática, a fim de confirmarmos os resultados. Primeiro, iremos realizar a padronização dos dados de entrada. Depois, treinaremos o modelo e exibiremos a acurácia de teste.
"""

# Avaliação do modelo com o conjunto de testes

# Preparação do modelo
scaler = StandardScaler().fit(X_train) # ajuste do scaler com o conjunto de treino
rescaledX = scaler.transform(X_train) # aplicação da padronização no conjunto de treino
model = LogisticRegression(max_iter=200,C=1,penalty='l2',solver='saga')
model.fit(rescaledX, y_train)

# Estimativa da acurácia no conjunto de teste
rescaledTestX = scaler.transform(X_test) # aplicação da padronização no conjunto de teste
predictions = model.predict(rescaledTestX)
print(accuracy_score(y_test, predictions))

"""Por meio do conjunto de teste, verificamos que alcançamos acurácia de 97,4% em dados não vistos. Esse resultado foi bastante próximo da nossa avaliação anterior da regressão logística, que alcançou acurácia média de 98%. Como temos um problema de classificação binária e um conjunto de dados balanceados, sem prevalência de uma classe em relação a outra, a métrica de acurácia
é adequada para avaliar o modelo de regressão logística e podemos inferir que não há problemas de overfitting ou underfitting. Valores semelhantes à acurácia de teste são esperados quando esse modelo estiver executando em produção e fazendo predições para novos dados.

Vamos agora preparar o modelo para utilização em produção. Para isso, vamos treiná-lo com todo o dataset, e não apenas o conjunto de treino.
"""

# Preparação do modelo com TODO o dataset
scaler = StandardScaler().fit(x) # ajuste do scaler com TODO o dataset
rescaledX = scaler.transform(x) # aplicação da padronização com TODO o dataset
model.fit(rescaledX, y)

"""## 5- Simulando a aplicação do modelo em dados não vistos

Finalmente, iremos simular a aplicação do modelo em dados não vistos, imaginando uma nova instância, mas que não sabemos a classe de saída. Poderemos, então, aplicar nosso modelo recém-treinado para fazer a predição da classe. Para tal, será necessário antes padronizar os dados utilizando a mesma escala dos dados usados no treinamento do modelo:
"""

# Novos dados - não sabemos a classe!
data = {'mean_concave_points':[0.1471],
        'worst_radius':[25.38],
        'worst_perimeter':[184.6],
        'worst_concave points':[0.2654],}

atributos = ['mean_concave_points',
             'worst_radius',
             'worst_perimeter',
             'worst_concave points']

entrada = pd.DataFrame(data, columns=atributos)

array_entrada = entrada.values
X_entrada = array_entrada[:,0:4].astype(float)

# Padronização nos dados de entrada usando o scaler utilizado em X
rescaledEntradaX = scaler.transform(X_entrada)
print(rescaledEntradaX)

"""Podemos agora realizar a predição das classes para os novos dados:"""

# Predição de classes dos dados de entrada
saidas = model.predict(rescaledEntradaX)
print(saidas)

"""O modelo de regressão logística é especialmente adequado para situações em que você está lidando com problemas de classificação binária, ou seja, quando precisa prever se uma observação pertence a uma de duas categorias possíveis. Não requer suposições sobre a disposição dos dados e possui uma boa performance em conjunto de dados pequenos a moderados."""